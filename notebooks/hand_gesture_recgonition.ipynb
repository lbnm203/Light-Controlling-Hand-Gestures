{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JZJH1v68YX4M"
   },
   "outputs": [],
   "source": [
    "# # Tạo folder data để các bạn upload file 3 file data được tạo ra ở step 0 vào folder data\n",
    "# # Các bạn upload file hand_gesture.yaml ngoài folder data\n",
    "# !mkdir data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L9QZbsqlXKvu"
   },
   "outputs": [],
   "source": [
    "# # Nếu đã chạy thành công step 0 thì các bạn không chạy cell này và chỉ upload 3 file data của các bạn vào thư mục data\n",
    "# # Và upload file hand_gesture.yaml bên ngoài thư mục data\n",
    "# # Nếu không chạy được ở step 0 thì các bạn run cell này để download data\n",
    "# !gdown  1gzWOtABiVmJ38usCSDe5F9gR2tECt3zu -O data/\n",
    "# !gdown  15lwipssmC_K82ukRfb0uVCiDH1TZ3QCf -O data/\n",
    "# !gdown  1nIo1_wBmkovz-u_BCsV5c1Kbz6ZqoKwq -O data/\n",
    "# # Download file hand_gesture.yam\n",
    "# !gdown  1ZteHYSgbuZu_GcUJHW8ZzoZv1DE8-oLw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kqhc2257_m3K",
    "outputId": "73102917-54a5-428c-e585-b356a7b9247d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mediapipe==0.10.18\n",
      "  Downloading mediapipe-0.10.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe==0.10.18) (1.4.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe==0.10.18) (24.2.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe==0.10.18) (24.3.25)\n",
      "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe==0.10.18) (0.4.33)\n",
      "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from mediapipe==0.10.18) (0.4.33)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe==0.10.18) (3.8.0)\n",
      "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from mediapipe==0.10.18) (1.26.4)\n",
      "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe==0.10.18) (4.10.0.84)\n",
      "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.10/dist-packages (from mediapipe==0.10.18) (4.25.5)\n",
      "Collecting sounddevice>=0.4.4 (from mediapipe==0.10.18)\n",
      "  Downloading sounddevice-0.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from mediapipe==0.10.18) (0.2.0)\n",
      "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe==0.10.18) (1.17.1)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe==0.10.18) (0.4.1)\n",
      "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe==0.10.18) (3.4.0)\n",
      "Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe==0.10.18) (1.13.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe==0.10.18) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe==0.10.18) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe==0.10.18) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe==0.10.18) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe==0.10.18) (24.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe==0.10.18) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe==0.10.18) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe==0.10.18) (2.8.2)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe==0.10.18) (2.22)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe==0.10.18) (1.16.0)\n",
      "Downloading mediapipe-0.10.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.1/36.1 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sounddevice-0.5.1-py3-none-any.whl (32 kB)\n",
      "Installing collected packages: sounddevice, mediapipe\n",
      "Successfully installed mediapipe-0.10.18 sounddevice-0.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe==0.10.18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SQmMu4bKVnkG",
    "outputId": "8da8aaed-1481-42ae-e275-7d944c67db60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchmetrics\n",
      "  Downloading torchmetrics-1.6.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.26.4)\n",
      "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.5.1+cu121)\n",
      "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
      "  Downloading lightning_utilities-0.11.9-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.1.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.16.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n",
      "Downloading torchmetrics-1.6.0-py3-none-any.whl (926 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m926.4/926.4 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lightning_utilities-0.11.9-py3-none-any.whl (28 kB)\n",
      "Installing collected packages: lightning-utilities, torchmetrics\n",
      "Successfully installed lightning-utilities-0.11.9 torchmetrics-1.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "xZPTB4Gm_8KF"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import yaml\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from  torch import nn\n",
    "import mediapipe as mp\n",
    "from torch import optim\n",
    "from datetime import datetime\n",
    "from torchmetrics import Accuracy\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "qdI0AaZt_38Q"
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        list_label = label_dict_from_config_file(\"hand_gesture.yaml\")\n",
    "\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            ################## Your Code Here ################## Q1\n",
    "            # Hoàn thành đoạn code để xây dựng một model gồm có 4 hidden layer,\n",
    "            # lần lượng input và output là (63, 128), (128, 128), (128, 128), (128, 128).\n",
    "            # Layer đầu tiên được theo sau bổi một Relu và Batchnorm1d.\n",
    "            # Layer thứ 2, 3, và 4 được theo sau bỏi Relu và Dropout với rate lần lượt là 0.4, 0.4, 0.6.\n",
    "            # Output layer có nhịêm vụ phân loại với input là 128 và output là số lượng class cử chỉ\n",
    "            ####################################################\n",
    "            nn.Linear(63, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.4),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.4),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.6),\n",
    "            nn.Linear(128, len(list_label)),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        ################## Your Code Here ################## Q2\n",
    "        ''' Hoàn thành code để thực hiện forward dự đoán cử chỉ với input x.\n",
    "        Thực hiệnt flatten x\n",
    "        Pass x vừa flatten vào linear_relu_stack\n",
    "        Return  logits (outputs từ layer cuối cùng)\n",
    "        '''\n",
    "        ####################################################\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "    def predict(self,x,threshold=0.8):\n",
    "        logits = self(x)\n",
    "        softmax_prob = nn.Softmax(dim=1)(logits)\n",
    "        chosen_ind = torch.argmax(softmax_prob,dim=1)\n",
    "        return torch.where(softmax_prob[0,chosen_ind]>threshold,chosen_ind,-1)\n",
    "\n",
    "    def predict_with_known_class(self,x):\n",
    "        logits = self(x)\n",
    "        softmax_prob = nn.Softmax(dim=1)(logits)\n",
    "        return torch.argmax(softmax_prob,dim=1)\n",
    "\n",
    "    def score(self,logits):\n",
    "        return -torch.amax(logits,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "lJUGNVftADWJ"
   },
   "outputs": [],
   "source": [
    "def label_dict_from_config_file(relative_path):\n",
    "    with open(relative_path,\"r\") as f:\n",
    "       label_tag = yaml.full_load(f)[\"gestures\"]\n",
    "    return label_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "3yzD6r0wTR0v"
   },
   "outputs": [],
   "source": [
    "class HandLandmarksDetector():\n",
    "    def __init__(self) -> None:\n",
    "        self.mp_drawing = mp.solutions.drawing_utils\n",
    "        self.mp_drawing_styles = mp.solutions.drawing_styles\n",
    "        self.mp_hands = mp.solutions.hands\n",
    "        self.detector = self.mp_hands.Hands(False,max_num_hands=1,min_detection_confidence=0.5)\n",
    "\n",
    "    def detectHand(self,frame):\n",
    "        hands = []\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        annotated_image = frame.copy()\n",
    "        results = self.detector.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        if results.multi_hand_landmarks is not None:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                hand = []\n",
    "                self.mp_drawing.draw_landmarks(\n",
    "                    annotated_image,\n",
    "                    hand_landmarks,\n",
    "                    self.mp_hands.HAND_CONNECTIONS,\n",
    "                    self.mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                    self.mp_drawing_styles.get_default_hand_connections_style())\n",
    "                for landmark in hand_landmarks.landmark:\n",
    "                    x,y,z = landmark.x,landmark.y,landmark.z\n",
    "                    hand.extend([x,y,z])\n",
    "            hands.append(hand)\n",
    "        return hands,annotated_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "DQH1LReLB03s"
   },
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, data_file):\n",
    "        self.data = pd.read_csv(data_file)\n",
    "        self.labels = torch.from_numpy(self.data.iloc[:,0].to_numpy())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        one_hot_label = self.labels[idx]\n",
    "        torch_data = torch.from_numpy(self.data.iloc[idx,1:].to_numpy(dtype=np.float32))\n",
    "        return torch_data, one_hot_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "h9prQCqNTXPS"
   },
   "outputs": [],
   "source": [
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.watched_metrics = np.inf\n",
    "\n",
    "    def early_stop(self, current_value):\n",
    "        if current_value < self.watched_metrics:\n",
    "            self.watched_metrics = current_value\n",
    "            self.counter = 0\n",
    "        elif current_value > (self.watched_metrics + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "fPBj338O_tcY"
   },
   "outputs": [],
   "source": [
    "def train(trainloader, val_loader, model, loss_function, early_stopper, optimizer):\n",
    "    # add auroc score\n",
    "    best_vloss = 1_000_000\n",
    "    timestamp = datetime.now().strftime('%d-%m %H:%M')\n",
    "    for epoch in range(300):\n",
    "        #training step\n",
    "        model.train(True)\n",
    "        running_loss = 0.0\n",
    "        acc_train = Accuracy(num_classes=len(LIST_LABEL), task='MULTICLASS')\n",
    "        for batch_number,data in enumerate(trainloader):\n",
    "            inputs,labels = data\n",
    "\n",
    "            ################## Your Code Here ################## Q9\n",
    "            ''' Hoàn thành code để thực hiện reset gradients và dự đoán class cử\n",
    "            chỉ của inputs\n",
    "            '''\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(inputs)\n",
    "            ####################################################\n",
    "\n",
    "            ################## Your Code Here ################## Q10\n",
    "            ''' Hoàn thành code để thực hiện tính loss dưa vào kết quả dự đoán\n",
    "            và labels, sau đó thực hiện backwward và update parameters thông qua\n",
    "            optimizer\n",
    "            '''\n",
    "\n",
    "            loss = loss_function(preds, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            ####################################################\n",
    "\n",
    "            acc_train.update(model.predict_with_known_class(inputs), labels)\n",
    "            running_loss += loss.item()\n",
    "        avg_loss = running_loss / len(trainloader)\n",
    "        # validating step\n",
    "        model.train(False)\n",
    "        running_vloss = 0.0\n",
    "        acc_val = Accuracy(num_classes=len(LIST_LABEL), task='MULTICLASS')\n",
    "        for i, vdata in enumerate(val_loader):\n",
    "            vinputs, vlabels = vdata\n",
    "            preds = model(vinputs)\n",
    "            vloss = loss_function(preds, vlabels)\n",
    "            running_vloss += vloss.item()\n",
    "            acc_val.update(model.predict_with_known_class(vinputs), vlabels)\n",
    "\n",
    "        # Log the running loss averaged per batch\n",
    "        # for both training and validation\n",
    "        print(f\"Epoch {epoch}: \")\n",
    "        print(f\"Accuracy train:{acc_train.compute().item()}, val:{acc_val.compute().item()}\")\n",
    "        avg_vloss = running_vloss / len(val_loader)\n",
    "        print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "        print('Training vs. Validation Loss',\n",
    "                        { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                        epoch + 1)\n",
    "        print('Training vs. Validation accuracy',\n",
    "                        { 'Training' : acc_train.compute().item()\n",
    "                        , 'Validation' : acc_val.compute().item() },\n",
    "                        epoch + 1)\n",
    "\n",
    "        # Track best performance, and save the model's state\n",
    "        if avg_vloss < best_vloss:\n",
    "            best_vloss = avg_vloss\n",
    "            best_model_path = f'./{save_path}/model_{timestamp}_{model.__class__.__name__}_best'\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "\n",
    "        if early_stopper.early_stop(avg_vloss):\n",
    "            ################## Your Code Here ################## Q5\n",
    "            ''' Hoàn thành đoạn code bên dưới để print ra epoch hiện tại và\n",
    "            minimum watched metric và thoát loop\n",
    "            '''\n",
    "\n",
    "            print(f\"Early stopping at epoch {epoch}, minimum validation loss: {early_stopper.watched_metrics}\")\n",
    "            break\n",
    "\n",
    "            ####################################################\n",
    "\n",
    "\n",
    "\n",
    "    model_path = f'./{save_path}/model_{timestamp}_{model.__class__.__name__}_last'\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    print(acc_val.compute())\n",
    "    return model, best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MhE1acacBG8z",
    "outputId": "fbb4b5ca-390a-4efe-a6c5-8562464c4737"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: \n",
      "Accuracy train:0.43161824345588684, val:0.6835548281669617\n",
      "LOSS train 1.6436784546426002 valid 1.5046320009231566\n",
      "Training vs. Validation Loss {'Training': 1.6436784546426002, 'Validation': 1.5046320009231566} 1\n",
      "Training vs. Validation accuracy {'Training': 0.43161824345588684, 'Validation': 0.6835548281669617} 1\n",
      "Epoch 1: \n",
      "Accuracy train:0.7006131410598755, val:0.9335548281669617\n",
      "LOSS train 1.0665577941752495 valid 0.8984629717469216\n",
      "Training vs. Validation Loss {'Training': 1.0665577941752495, 'Validation': 0.8984629717469216} 2\n",
      "Training vs. Validation accuracy {'Training': 0.7006131410598755, 'Validation': 0.9335548281669617} 2\n",
      "Epoch 2: \n",
      "Accuracy train:0.9322847127914429, val:0.9460132718086243\n",
      "LOSS train 0.4466390222945112 valid 0.4657391523383558\n",
      "Training vs. Validation Loss {'Training': 0.4466390222945112, 'Validation': 0.4657391523383558} 3\n",
      "Training vs. Validation accuracy {'Training': 0.9322847127914429, 'Validation': 0.9460132718086243} 3\n",
      "Epoch 3: \n",
      "Accuracy train:0.9941349029541016, val:0.9460132718086243\n",
      "LOSS train 0.1315080040788397 valid 0.4209083448862657\n",
      "Training vs. Validation Loss {'Training': 0.1315080040788397, 'Validation': 0.4209083448862657} 4\n",
      "Training vs. Validation accuracy {'Training': 0.9941349029541016, 'Validation': 0.9460132718086243} 4\n",
      "Epoch 4: \n",
      "Accuracy train:0.9984004497528076, val:0.9460132718086243\n",
      "LOSS train 0.05317808354788638 valid 0.5180802190350369\n",
      "Training vs. Validation Loss {'Training': 0.05317808354788638, 'Validation': 0.5180802190350369} 5\n",
      "Training vs. Validation accuracy {'Training': 0.9984004497528076, 'Validation': 0.9460132718086243} 5\n",
      "Epoch 5: \n",
      "Accuracy train:0.9986670017242432, val:0.9460132718086243\n",
      "LOSS train 0.02537985820263783 valid 0.5586855810461566\n",
      "Training vs. Validation Loss {'Training': 0.02537985820263783, 'Validation': 0.5586855810461566} 6\n",
      "Training vs. Validation accuracy {'Training': 0.9986670017242432, 'Validation': 0.9460132718086243} 6\n",
      "Epoch 6: \n",
      "Accuracy train:0.9997333884239197, val:0.9460132718086243\n",
      "LOSS train 0.016477667421914956 valid 0.6668149935551628\n",
      "Training vs. Validation Loss {'Training': 0.016477667421914956, 'Validation': 0.6668149935551628} 7\n",
      "Training vs. Validation accuracy {'Training': 0.9997333884239197, 'Validation': 0.9460132718086243} 7\n",
      "Epoch 7: \n",
      "Accuracy train:0.9986670017242432, val:0.9460132718086243\n",
      "LOSS train 0.012813638921757724 valid 0.6760353247586317\n",
      "Training vs. Validation Loss {'Training': 0.012813638921757724, 'Validation': 0.6760353247586317} 8\n",
      "Training vs. Validation accuracy {'Training': 0.9986670017242432, 'Validation': 0.9460132718086243} 8\n",
      "Epoch 8: \n",
      "Accuracy train:0.9992002248764038, val:0.9460132718086243\n",
      "LOSS train 0.009179632049400676 valid 0.7092288428408392\n",
      "Training vs. Validation Loss {'Training': 0.009179632049400676, 'Validation': 0.7092288428408392} 9\n",
      "Training vs. Validation accuracy {'Training': 0.9992002248764038, 'Validation': 0.9460132718086243} 9\n",
      "Epoch 9: \n",
      "Accuracy train:0.9997333884239197, val:0.9460132718086243\n",
      "LOSS train 0.006610644506934555 valid 0.6916699138860167\n",
      "Training vs. Validation Loss {'Training': 0.006610644506934555, 'Validation': 0.6916699138860167} 10\n",
      "Training vs. Validation accuracy {'Training': 0.9997333884239197, 'Validation': 0.9460132718086243} 10\n",
      "Epoch 10: \n",
      "Accuracy train:1.0, val:0.9460132718086243\n",
      "LOSS train 0.005730257702723859 valid 0.7309627501218802\n",
      "Training vs. Validation Loss {'Training': 0.005730257702723859, 'Validation': 0.7309627501218802} 11\n",
      "Training vs. Validation accuracy {'Training': 1.0, 'Validation': 0.9460132718086243} 11\n",
      "Epoch 11: \n",
      "Accuracy train:1.0, val:0.9460132718086243\n",
      "LOSS train 0.004552062853806692 valid 0.7974918019471261\n",
      "Training vs. Validation Loss {'Training': 0.004552062853806692, 'Validation': 0.7974918019471261} 12\n",
      "Training vs. Validation accuracy {'Training': 1.0, 'Validation': 0.9460132718086243} 12\n",
      "Epoch 12: \n",
      "Accuracy train:1.0, val:0.9460132718086243\n",
      "LOSS train 0.0033008490557202754 valid 0.8175280065465585\n",
      "Training vs. Validation Loss {'Training': 0.0033008490557202754, 'Validation': 0.8175280065465585} 13\n",
      "Training vs. Validation accuracy {'Training': 1.0, 'Validation': 0.9460132718086243} 13\n",
      "Epoch 13: \n",
      "Accuracy train:1.0, val:0.9460132718086243\n",
      "LOSS train 0.0033877804612820134 valid 0.8746530098584253\n",
      "Training vs. Validation Loss {'Training': 0.0033877804612820134, 'Validation': 0.8746530098584253} 14\n",
      "Training vs. Validation accuracy {'Training': 1.0, 'Validation': 0.9460132718086243} 14\n",
      "Epoch 14: \n",
      "Accuracy train:1.0, val:0.9460132718086243\n",
      "LOSS train 0.002587573257265018 valid 0.929415503813376\n",
      "Training vs. Validation Loss {'Training': 0.002587573257265018, 'Validation': 0.929415503813376} 15\n",
      "Training vs. Validation accuracy {'Training': 1.0, 'Validation': 0.9460132718086243} 15\n",
      "Epoch 15: \n",
      "Accuracy train:1.0, val:0.9460132718086243\n",
      "LOSS train 0.0027322801217954467 valid 0.8823229819911285\n",
      "Training vs. Validation Loss {'Training': 0.0027322801217954467, 'Validation': 0.8823229819911285} 16\n",
      "Training vs. Validation accuracy {'Training': 1.0, 'Validation': 0.9460132718086243} 16\n",
      "Epoch 16: \n",
      "Accuracy train:1.0, val:0.9460132718086243\n",
      "LOSS train 0.0020608898231968967 valid 0.8948138062751673\n",
      "Training vs. Validation Loss {'Training': 0.0020608898231968967, 'Validation': 0.8948138062751673} 17\n",
      "Training vs. Validation accuracy {'Training': 1.0, 'Validation': 0.9460132718086243} 17\n",
      "Epoch 17: \n",
      "Accuracy train:0.9994668364524841, val:0.9460132718086243\n",
      "LOSS train 0.0015490841910155103 valid 0.892631306712002\n",
      "Training vs. Validation Loss {'Training': 0.0015490841910155103, 'Validation': 0.892631306712002} 18\n",
      "Training vs. Validation accuracy {'Training': 0.9994668364524841, 'Validation': 0.9460132718086243} 18\n",
      "Epoch 18: \n",
      "Accuracy train:0.9994668364524841, val:0.9460132718086243\n",
      "LOSS train 0.0027881113252233455 valid 0.9875449058906159\n",
      "Training vs. Validation Loss {'Training': 0.0027881113252233455, 'Validation': 0.9875449058906159} 19\n",
      "Training vs. Validation accuracy {'Training': 0.9994668364524841, 'Validation': 0.9460132718086243} 19\n",
      "Epoch 19: \n",
      "Accuracy train:1.0, val:0.9460132718086243\n",
      "LOSS train 0.0011797259082820173 valid 0.974940637957078\n",
      "Training vs. Validation Loss {'Training': 0.0011797259082820173, 'Validation': 0.974940637957078} 20\n",
      "Training vs. Validation accuracy {'Training': 1.0, 'Validation': 0.9460132718086243} 20\n",
      "Epoch 20: \n",
      "Accuracy train:1.0, val:0.9460132718086243\n",
      "LOSS train 0.001752431702582126 valid 0.920321131121511\n",
      "Training vs. Validation Loss {'Training': 0.001752431702582126, 'Validation': 0.920321131121511} 21\n",
      "Training vs. Validation accuracy {'Training': 1.0, 'Validation': 0.9460132718086243} 21\n",
      "Epoch 21: \n",
      "Accuracy train:1.0, val:0.9460132718086243\n",
      "LOSS train 0.0010459998508675662 valid 0.9650388761922457\n",
      "Training vs. Validation Loss {'Training': 0.0010459998508675662, 'Validation': 0.9650388761922457} 22\n",
      "Training vs. Validation accuracy {'Training': 1.0, 'Validation': 0.9460132718086243} 22\n",
      "Epoch 22: \n",
      "Accuracy train:1.0, val:0.9460132718086243\n",
      "LOSS train 0.0011568451576982005 valid 1.0705845602801494\n",
      "Training vs. Validation Loss {'Training': 0.0011568451576982005, 'Validation': 1.0705845602801494} 23\n",
      "Training vs. Validation accuracy {'Training': 1.0, 'Validation': 0.9460132718086243} 23\n",
      "Epoch 23: \n",
      "Accuracy train:1.0, val:0.9460132718086243\n",
      "LOSS train 0.0009855150376600424 valid 0.9951631572705654\n",
      "Training vs. Validation Loss {'Training': 0.0009855150376600424, 'Validation': 0.9951631572705654} 24\n",
      "Training vs. Validation accuracy {'Training': 1.0, 'Validation': 0.9460132718086243} 24\n",
      "Epoch 24: \n",
      "Accuracy train:1.0, val:0.9460132718086243\n",
      "LOSS train 0.0008744162729039709 valid 1.0430660391789288\n",
      "Training vs. Validation Loss {'Training': 0.0008744162729039709, 'Validation': 1.0430660391789288} 25\n",
      "Training vs. Validation accuracy {'Training': 1.0, 'Validation': 0.9460132718086243} 25\n",
      "Epoch 25: \n",
      "Accuracy train:1.0, val:0.9460132718086243\n",
      "LOSS train 0.0014242989583819624 valid 0.9748849383715565\n",
      "Training vs. Validation Loss {'Training': 0.0014242989583819624, 'Validation': 0.9748849383715565} 26\n",
      "Training vs. Validation accuracy {'Training': 1.0, 'Validation': 0.9460132718086243} 26\n",
      "Epoch 26: \n",
      "Accuracy train:1.0, val:0.9460132718086243\n",
      "LOSS train 0.0006311259215258457 valid 1.0256765520076954\n",
      "Training vs. Validation Loss {'Training': 0.0006311259215258457, 'Validation': 1.0256765520076954} 27\n",
      "Training vs. Validation accuracy {'Training': 1.0, 'Validation': 0.9460132718086243} 27\n",
      "Epoch 27: \n",
      "Accuracy train:1.0, val:0.9460132718086243\n",
      "LOSS train 0.0009304976506911694 valid 1.0980897475143612\n",
      "Training vs. Validation Loss {'Training': 0.0009304976506911694, 'Validation': 1.0980897475143612} 28\n",
      "Training vs. Validation accuracy {'Training': 1.0, 'Validation': 0.9460132718086243} 28\n",
      "Epoch 28: \n",
      "Accuracy train:1.0, val:0.9460132718086243\n",
      "LOSS train 0.000772116537779979 valid 1.0674775398219873\n",
      "Training vs. Validation Loss {'Training': 0.000772116537779979, 'Validation': 1.0674775398219873} 29\n",
      "Training vs. Validation accuracy {'Training': 1.0, 'Validation': 0.9460132718086243} 29\n",
      "Epoch 29: \n",
      "Accuracy train:1.0, val:0.9460132718086243\n",
      "LOSS train 0.00048815690042055334 valid 1.1346008892958783\n",
      "Training vs. Validation Loss {'Training': 0.00048815690042055334, 'Validation': 1.1346008892958783} 30\n",
      "Training vs. Validation accuracy {'Training': 1.0, 'Validation': 0.9460132718086243} 30\n",
      "Epoch 30: \n",
      "Accuracy train:1.0, val:0.9460132718086243\n",
      "LOSS train 0.0005375518637284837 valid 1.187367810820855\n",
      "Training vs. Validation Loss {'Training': 0.0005375518637284837, 'Validation': 1.187367810820855} 31\n",
      "Training vs. Validation accuracy {'Training': 1.0, 'Validation': 0.9460132718086243} 31\n",
      "Epoch 31: \n",
      "Accuracy train:0.9997333884239197, val:0.9460132718086243\n",
      "LOSS train 0.0006158330518972318 valid 1.143138850112698\n",
      "Training vs. Validation Loss {'Training': 0.0006158330518972318, 'Validation': 1.143138850112698} 32\n",
      "Training vs. Validation accuracy {'Training': 0.9997333884239197, 'Validation': 0.9460132718086243} 32\n",
      "Epoch 32: \n",
      "Accuracy train:0.9997333884239197, val:0.9460132718086243\n",
      "LOSS train 0.0004373279182781265 valid 1.156483371829938\n",
      "Training vs. Validation Loss {'Training': 0.0004373279182781265, 'Validation': 1.156483371829938} 33\n",
      "Training vs. Validation accuracy {'Training': 0.9997333884239197, 'Validation': 0.9460132718086243} 33\n",
      "Epoch 33: \n",
      "Accuracy train:0.9997333884239197, val:0.9460132718086243\n",
      "LOSS train 0.00028605073370311 valid 1.1267908817288876\n",
      "Training vs. Validation Loss {'Training': 0.00028605073370311, 'Validation': 1.1267908817288876} 34\n",
      "Training vs. Validation accuracy {'Training': 0.9997333884239197, 'Validation': 0.9460132718086243} 34\n",
      "Early stopping at epoch 33, minimum validation loss: 0.4209083448862657\n",
      "tensor(0.9460)\n"
     ]
    }
   ],
   "source": [
    "DATA_FOLDER_PATH=\"./data/\"\n",
    "LIST_LABEL = label_dict_from_config_file(\"hand_gesture.yaml\")\n",
    "train_path = os.path.join(DATA_FOLDER_PATH,\"landmark_train.csv\")\n",
    "val_path = os.path.join(DATA_FOLDER_PATH,\"landmark_val.csv\")\n",
    "save_path = './models'\n",
    "os.makedirs(save_path,exist_ok=True)\n",
    "\n",
    "trainset = CustomImageDataset(train_path)\n",
    "################## Your Code Here ################## Q3\n",
    "'''Hoàn thành code để thực hiện khởi tạo DataLoader cho trainset với\n",
    "batch_size 40 và cho phép xáo trộn\n",
    "'''\n",
    "trainloader = torch.utils.data.DataLoader(trainset,batch_size=40, shuffle=True)\n",
    "####################################################\n",
    "\n",
    "valset = CustomImageDataset(os.path.join(val_path))\n",
    "val_loader = torch.utils.data.DataLoader(valset,batch_size=50, shuffle=False)\n",
    "\n",
    "################## Your Code Here ################## Q8\n",
    "'''Hoàn thành code để thực hiện khởi tạo NeuralNetwork model đã xây dựng ở trên,\n",
    "khởi tạo hàm loss sử dụng CrossEntropyLoss và khởi tạo early stopper với patience\n",
    "là 30 và min_delta là 0.01\n",
    "'''\n",
    "model = NeuralNetwork()\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "early_stopper = EarlyStopper(patience=30, min_delta=0.01)\n",
    "####################################################\n",
    "\n",
    "################## Your Code Here ################## Q4\n",
    "'''Hoàn thành code để thực hiện cấu hình Adam optimizer cho các tham số của\n",
    "model với tốc độ học là 0.0001\n",
    "'''\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "####################################################\n",
    "\n",
    "\n",
    "model, best_model_path = train(trainloader, val_loader, model, loss_function, early_stopper, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WuKEiiC_BWDM",
    "outputId": "ae5c8b85-1b8f-4078-faf5-d042be0303ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork\n",
      "Accuracy of model:1.0\n",
      "========================================================================\n"
     ]
    }
   ],
   "source": [
    "list_label = label_dict_from_config_file(\"hand_gesture.yaml\")\n",
    "DATA_FOLDER_PATH=\"./data/\"\n",
    "testset = CustomImageDataset(os.path.join(DATA_FOLDER_PATH,\"landmark_test.csv\"))\n",
    "\n",
    "# Test DataLoader instantiation\n",
    "################## Your Code Here ################## Q6\n",
    "''' Hoàn thành code bên dưới để  khởi tạo DataLoader cho testset with batch size\n",
    "20, không cho phép shuffle\n",
    "'''\n",
    "test_loader = torch.utils.data.DataLoader(testset,batch_size=20, shuffle=False)\n",
    "####################################################\n",
    "\n",
    "\n",
    "\n",
    "network = NeuralNetwork()\n",
    "network.load_state_dict(torch.load(best_model_path, weights_only=False))\n",
    "\n",
    "network.eval()\n",
    "acc_test = Accuracy(num_classes=len(list_label), task='MULTICLASS')\n",
    "for i, test_data in enumerate(test_loader):\n",
    "    test_input, test_label = test_data\n",
    "    ################## Your Code Here ################## Q7\n",
    "    '''Hoàn thành code bên dưới để  predict class của cử chỉ và update accuracy\n",
    "    với kết quả predict và true labels\n",
    "    '''\n",
    "    preds = network(test_input)\n",
    "    acc_test.update(preds, test_label)\n",
    "\n",
    "    ####################################################\n",
    "\n",
    "print(network.__class__.__name__)\n",
    "print(f\"Accuracy of model:{acc_test.compute().item()}\")\n",
    "print(\"========================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "569TTudlZoz6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
